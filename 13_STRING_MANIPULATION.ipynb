{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IqwhQmEpE6PL"
   },
   "source": [
    "<b> Thực hành String manipulation  <b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yeQcLE5x9FWE"
   },
   "outputs": [],
   "source": [
    "movie = 'fox and kelley soon become bitter rivals because the new fox books store is opening up right across the block from the small business .'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kmy55prj9Oxh",
    "outputId": "a4f172d0-0dca-440e-dba2-f834dcd07a39"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Đếm số ký tựtự trong chuỗi \n",
    "length_string = len(movie)\n",
    "length_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0811JgxC9ZN5"
   },
   "outputs": [],
   "source": [
    "movie1 = 'the most significant tension of _election_ is the potential relationship between a teacher and his student .'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_-O3teFq9cjX"
   },
   "outputs": [],
   "source": [
    "movie2 = 'the most significant tension of _rushmore_ is the potential relationship between a teacher and his student .'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "rDQHvuJV9R4O",
    "outputId": "e7f583a3-0531-4563-d603-2e8b992ba9ce"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'the most significant tension of '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the first 32 characters of movie1 - Chọn 32 ký tự đầu của movie1\n",
    "first_part = movie1[0:32]\n",
    "first_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "UepLN2PF9g2h",
    "outputId": "9c721bbd-ea24-491c-dd02-a278663768be"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'gnificant tension o'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extract the substring from the 12th to the 30th character from the variable movie which corresponds to the movie title. Store it in the variable movie_title.\n",
    "# Tách chuỗi ra từ ký tự 12 đến ký tự 30 trong chuỗi movie có chứa movie title. Lưu chuỗi đã tách vào biến movie title \n",
    "# Get the word\n",
    "movie_title = movie1[11:30]\n",
    "movie_title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W2osGMp-9wRX"
   },
   "source": [
    "Get the palindrome by reversing the string contained in movie_title.\n",
    "Đảo chuỗi trong biến movie_title, lưu vào biến palindrome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "hLItR3Vp9o4M",
    "outputId": "9d7c6dac-2a36-4556-d189-383081e1b771"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'o noisnet tnacifing'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtain the palindrome\n",
    "palindrome = movie_title[::-1]  #[a:b:c] -> lấy từ a đến b bước nhảy c\n",
    "palindrome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z4v_yBvB95Wn"
   },
   "source": [
    "Complete the code to print out the movie_title if it is a palindrome.\n",
    "Check xem movie_title có phải là chuỗi palindrome không "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oCQXdusq95uY"
   },
   "outputs": [],
   "source": [
    "# Print the word if it's a palindrome\n",
    "if movie_title == palindrome:\n",
    "\tprint(movie_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1PFdsFc0vT67"
   },
   "source": [
    "Practice 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eI9L-pce-WSa"
   },
   "outputs": [],
   "source": [
    "movie = '$I supposed that coming from MTV Films I should expect no less$<\\i'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QMeLv-iY-bKn"
   },
   "source": [
    "Convert the string in the variable movie to lowercase. Print the result.\n",
    "Convert chuỗi trong biến movie sang lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EaMgdKXg-XXH",
    "outputId": "03388a00-fe65-42f3-dd2d-ff51afd38547"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$i supposed that coming from mtv films i should expect no less$<\\i\n"
     ]
    }
   ],
   "source": [
    "# Convert to lowercase and print the result\n",
    "movie_lower = movie.lower()\n",
    "print(movie_lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "56c6GkIa-x7p"
   },
   "source": [
    "Remove tag <\\i> from the end of the string. Print the results.\n",
    "Removie tag <\\i> ở đoạn cuối của chuỗi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5VJy0bkU-xE0",
    "outputId": "c41af26c-79b6-4330-c1dc-34348aeebd0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$I supposed that coming from MTV Films I should expect no less$\n"
     ]
    }
   ],
   "source": [
    "# Remove tags happening at the end and print results\n",
    "movie_tag = movie.replace(\"<\\i\",\"\")\n",
    "print(movie_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M76rf1ln-1JB"
   },
   "outputs": [],
   "source": [
    "file = 'mtv films election, a high school comedy, is a current example\\nfrom there, director steven spielberg wastes no time, taking us into the water on a midnight swim'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rHTFpfx8_I7n"
   },
   "source": [
    "Split the string file into many substrings at line boundaries.\n",
    "Print out the resulting variable file_split.\n",
    "Complete the for-loop to split the strings into many substrings using commas as a separator element.\n",
    "\n",
    "Tách chuỗi thành nhiều chuỗi nhỏ tại line boundaries (\\n) , sau đó lưu lại kết quả trong file_split\n",
    "Dùng for loop để tách chuỗi trong các chuỗi nhỏ , ngăn cách bởi dấu phẩy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Svqjrfa6-_-I",
    "outputId": "76bf54f9-4bf8-4bc9-d6c4-d1db57359426"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mtv films election, a high school comedy, is a current example', 'from there, director steven spielberg wastes no time, taking us into the water on a midnight swim']\n",
      "['mtv films election', ' a high school comedy', ' is a current example']\n",
      "['from there', ' director steven spielberg wastes no time', ' taking us into the water on a midnight swim']\n"
     ]
    }
   ],
   "source": [
    "# Split string at line boundaries\n",
    "file_split = file.splitlines()  #spilitlines() tách các chuỗi nhỏ sau \\n\n",
    "\n",
    "# Print file_split\n",
    "print(file_split)\n",
    "\n",
    "# Complete for-loop to split by commas\n",
    "for substring in file_split:\n",
    "    substring_split = substring.split(\",\")\n",
    "    print(substring_split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9AsKcWs7BX40"
   },
   "outputs": [],
   "source": [
    "movie = {200:\"it's clear that he's passionate about his beliefs , and that he's not just a punk looking for an excuse to beat people up .\",201:'I believe you I always said that the actor actor actor is amazing in every movie he has played'\n",
    ",202:\"it's astonishing how frightening the actor actor norton looks with a shaved head and a swastika on his chest.\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d5d-RHi7Cy7j",
    "outputId": "27f97ec9-253a-4714-b03d-b4e11049bfbf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([\"it's clear that he's passionate about his beliefs , and that he's not just a punk looking for an excuse to beat people up .\", 'I believe you I always said that the actor actor actor is amazing in every movie he has played', \"it's astonishing how frightening the actor actor norton looks with a shaved head and a swastika on his chest.\"])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = movie.values()\n",
    "movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jn7V-LwRDREx"
   },
   "source": [
    "Find if the substring actor occurs between the characters with index 37 and 41 inclusive. If it is not detected, print the statement Word not found.\n",
    "Replace actor actor with the substring actor if actor occurs only two repeated times.\n",
    "Replace actor actor actor with the substring actor if actor appears three repeated times.\n",
    "\n",
    "Tìm nếu substring actor xuất hiện từ ký tự 37 đến 41, nếu không thấy, print Word not found. \n",
    "\n",
    "Replace actor actor với substring actor nếu actor lặp lại 2 lần. \n",
    "Replace actor actor actor với substring actor nếu actor lặp lại 3 lần. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dxK0_eM2Cbdb",
    "outputId": "a065f97d-c057-49cb-c4c3-b1f91ff3b2d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word not found\n",
      "I believe you I always said that the actor is amazing in every movie he has played\n",
      "it's astonishing how frightening the actor norton looks with a shaved head and a swastika on his chest.\n"
     ]
    }
   ],
   "source": [
    "for movie in movies:\n",
    "  \t# Find if actor occurrs between 37 and 41 inclusive\n",
    "    if movie.find(\"actor\", 37, 42) == -1:  #tìm 'actor' trong khoảng 37 đến 42, nếu có thì trả về số của vị trí xuất hiện đầu tiên, nếu ko tìm ra thì trả kquả -1\n",
    "        print(\"Word not found\")\n",
    "    # Count occurrences and replace two by one\n",
    "    elif movie.count(\"actor\") == 2:  \n",
    "        print(movie.replace(\"actor actor\", \"actor\"))\n",
    "    else:\n",
    "        # Replace three occurrences by one\n",
    "        print(movie.replace(\"actor actor actor\", \"actor\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n_ST6Emnrhql",
    "outputId": "92841024-3b8f-47f7-c886-d5d59015318e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie.find(\"actor\", 37, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AUeNlpu0Dldh"
   },
   "outputs": [],
   "source": [
    "movies = (\"heck , jackie doesn't even have enough money for a haircut , looks like , much less a personal hairstylist .\"\n",
    ",\"in condor , chan plays the same character he's always played , himself , a mixture of bruce lee and tim allen , a master of both kung-fu and slapstick-fu .\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "huQtqeggDZtr"
   },
   "source": [
    "Find the index where money occurs between characters with index 12 and 50. If not found, the method should return -1.\n",
    "Tìm index của \"money\" trong khoảng ký tự từ 12 đến 50, nếu không thấy ,kết quả sẽ được trả là -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BiWOM2yWDU52",
    "outputId": "a2141834-c465-4770-eab6-1d9d4e7ca5a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "for movie in movies:\n",
    "  # Find the first occurrence of word\n",
    "  print(movie.find(\"money\", 12, 51))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dG-8soW8EIoE"
   },
   "source": [
    "Find the index where money occurs between characters with index 12 and 50. If not found, it should raise an error.\n",
    "\n",
    "Tìm index \"money\" trong khoảng ký tự 12 - 50, nếu không thấy, sẽ báo error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-cGIbyp9DfVe",
    "outputId": "ca581917-5220-4ea1-cc95-bcd4ae449b62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "substring not found\n"
     ]
    }
   ],
   "source": [
    "# vòng lặp for sẽ dừng lại nếu gặp lỗi ==> Try - Except: Try sẽ chạy tiếp, Except nếu lỗi print \"substring not found\"\n",
    "for movie in movies:\n",
    "  try:   \n",
    "    # Find the first occurrence of word\n",
    "  \tprint(movie.index(\"money\", 12, 51))\n",
    "  except ValueError:\n",
    "    print(\"substring not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2LycOjz1EvMm"
   },
   "source": [
    "Replacing words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KzSkrPjxEXmv"
   },
   "outputs": [],
   "source": [
    "movies = \"the rest of the story isn't important because all it does is serve as a mere backdrop for the two stars to share the screen .\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ra44BmsVErR0"
   },
   "source": [
    "Replace the substring isn't with the word is. Thay thế isn't bằng is <br>\n",
    "Replace the substring important with the word insignificant. Thay thế important bằng insignificant<br>\n",
    "Print out the result contained in the variable movies_antonym. Print kết quả được lưu trong biến movies_antonym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yCGD7F2YEa-x"
   },
   "outputs": [],
   "source": [
    "# Replace negations \n",
    "movies_no_negation = movies.replace(\"isn't\", \"is\")\n",
    "\n",
    "# Replace important\n",
    "movies_antonym = movies_no_negation.replace(\"important\", \"insignificant\")\n",
    "\n",
    "# Print out\n",
    "print(movies_antonym)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eJIS_yOzFOMH"
   },
   "source": [
    "Your company is analyzing the best way to provide users with different online courses. Your job is to scrape Wikipedia pages searching for tools used in Data Science subfields. You'll store the tool and field name in a database. After a text analysis, you realize that the information is provided in a specific position of the text but sometimes the field name is given first and the tool after that, while in other cases it's the other way around.\n",
    "\n",
    "You decide to use positional formatting to handle these situations because it provides a way to reorder placeholders.\n",
    "\n",
    "Công ty bạn đang phân tích tìm ra cách tốt nhất để cung cấp khóa học online cho users. Công việc của bạn là cào các trang wikipedia để tìm thông tin các tools được dùng trong Data Science. Bạn sẽ lưu tool và field name vào csdl. Sau khi phân tích kết quả thu được, bạn nhận ra là thông tin được đưa ra ở vị trí cố định trong text nhưng thỉnh thoảng field name lại đưa ra trước tool, và ngược lại. \n",
    "\n",
    "Bạn muốn dùng positional formatting để fix những trường hợp nàynày"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hKjSrLPAFVwP"
   },
   "outputs": [],
   "source": [
    "wikipedia_article = 'In computer science, artificial intelligence (AI), sometimes called machine intelligence, is intelligence demonstrated by machines, in contrast to the natural intelligence displayed by humans and animals.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cs6hmecvFch5"
   },
   "outputs": [],
   "source": [
    "my_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AI2NBLNyFNaL",
    "outputId": "8fb9283e-964f-4d89-ff05-b3769da4cc7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computer science\n",
      "artificial intelligence\n"
     ]
    }
   ],
   "source": [
    "# Assign the substrings to the variables\n",
    "first_pos = wikipedia_article[3:19].lower()\n",
    "second_pos = wikipedia_article[21:44].lower()\n",
    "print(first_pos)\n",
    "print(second_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sD9po114FqUx"
   },
   "source": [
    "You have created your database with the tools and the different Data Science subfields they are used in. The company is considering creating courses using these tools and sending personalized emails to the users recommending the different topics. They have asked you to make this process more time-efficient. To do this, you want to create a template email with a standard message changing the different tools and corresponding field name.\n",
    "\n",
    "First, you want to try doing this with just one example as a proof of concept. You use positional formatting and named placeholders to call the variables in a dictionary.\n",
    "\n",
    "Bạn đã tạo csdl chứa tools và subfields được sử dụng. Công ty đang xem xét làm ra những course về tool này và sẽ gửi mail đến những người thích hợp. Để tiết kiệm thời gian và công sức, công ty yêu cầu bạn làm ra 1 template email, chỉ cần thay đổi tên tool và tên fieldname vào emai. \n",
    "\n",
    "Bạn dùng positional formatting để làm , email sẽ gọi trực tiếp các biến cần thay đổi được lưulưu trong các dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vuDMvYoaFxmF"
   },
   "outputs": [],
   "source": [
    "courses = ['artificial intelligence', 'neural networks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ebv_x96oFnbt",
    "outputId": "a0ced007-8a9b-460a-c32f-4b4f0da962ba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'field': 'artificial intelligence', 'tool': 'neural networks'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dictionary\n",
    "plan = {\n",
    "  \t\t\"field\": courses[0],\n",
    "        \"tool\": courses[1]\n",
    "        }\n",
    "plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hD5NWYwTF-is"
   },
   "source": [
    "It's lunch time and you are talking with some of your colleagues. They comment that they feel that every morning someone should send them a reminder of what day it is so they can check in the calendar what their assignments are for that day.\n",
    "\n",
    "You want to help out and decide to write a small script that takes the date and time of the day so that every morning, a message is sent to your colleagues. You can use the module datetime along with named placeholders to achieve your goal.\n",
    "\n",
    "The date should be expressed as Month day, year, e.g. April 16, 2019 and the time as hh:mm, e.g. 16:30.\n",
    "\n",
    "Đồng nghiệp yêu cầu bạn làm 1 reminder cho họ rằng hôm nay là thứ mấy mỗi sáng để họ có thể check công việc trong ngày hôm đó. \n",
    "\n",
    "Bạn viết 1 script nhỏ lấy ngày và thời gian trong ngày để mỗi sáng, 1 tin nhắn sẽ tự động gửi đến đồng nghiệp của bạn. \n",
    "\n",
    "Format của datetime đó là Month , day , year. Ví dụ April 16 , 2019 và thời gian là hh : mm , ví dụ : 16:30 . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rVzBrPQKGB3G",
    "outputId": "d4784aa2-abb7-44ed-c86d-460748925596"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good morning. Today is September 29, 2022. It's 16:08 ... time to work!\n"
     ]
    }
   ],
   "source": [
    "# Import datetime \n",
    "from datetime import datetime\n",
    "\n",
    "# Assign date to get_date\n",
    "get_date = datetime.now()\n",
    "\n",
    "# Add named placeholders with format specifiers\n",
    "message = \"Good morning. Today is {today:%B %d, %Y}. It's {today:%H:%M} ... time to work!\" # %d -> hiện ngày   %B -> hiện tháng = chữ   %b --> hiện 3 chữ đầu\n",
    "\n",
    "# Format date\n",
    "print(message.format(today=get_date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cu6Jh4APG8o9"
   },
   "source": [
    "Formatted String ( fstring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vZENSrnXHXFu"
   },
   "source": [
    "you remember that you've created a website that displayed data science facts but it was too slow. You think that it could be due to the string formatting you used. Because f-strings are very fast and easy to use, you decide to rewrite that project.\n",
    "\n",
    "Bạn nhớ rằng bạn đã tạo ra 1 website data science nhưng nó quá chậm, và có thể là do định dạng chuỗi bạn dùng, nên bạn muốn viết lại website và sử dụng f-stringsstrings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jWgYaHtUG_Y9"
   },
   "outputs": [],
   "source": [
    "field1 = 'sexiest job'\n",
    "field2 = 'data is produced daily'\n",
    "field3 = 'Individuals'\n",
    "fact1 = 21\n",
    "fact2 = 2500000000000000000\n",
    "fact3 = 72.41415415151\n",
    "fact4 = 1.09"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ETIsbEbmHdFW"
   },
   "source": [
    "Data science is considered 'sexiest job' in the 21st century\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Edf2kDIXG-s8",
    "outputId": "3a238d5d-4ce1-4e24-b83e-21439333848b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data science is considered 'sexiest job' in the 21st century\n"
     ]
    }
   ],
   "source": [
    "# Complete the f-string\n",
    "print(f\"Data science is considered {field1!r} in the {fact1:d}st century\")  #f thì {} mới chạy, !r giữ cả dấu nháy, :d chuyển về dạng decimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UeU7T3-t9_TI",
    "outputId": "976646a7-d48a-4f84-8330-70e46e0818f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data science is considered sexiest job in the 21st century\n"
     ]
    }
   ],
   "source": [
    "print(\"Data science is considered {} in the {}st century\".format(field1,fact1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NfUt5cnoHk1P"
   },
   "outputs": [],
   "source": [
    "number1 = 120\n",
    "number2 = 7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x0kBMzceH5Hr"
   },
   "source": [
    "120 tweets were downloaded in 7 minutes indicating a speed of 17.1 tweets per min\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wKalBU3EHift",
    "outputId": "a5b4b703-111d-4c67-b2ac-fd5b6d3cc500"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 tweets were downloaded in 7 minutes indicating a speed of 17.1 tweets per min\n"
     ]
    }
   ],
   "source": [
    "# Include both variables and the result of dividing them \n",
    "print(f\"{number1} tweets were downloaded in {number2} minutes indicating a speed of {(number1/number2):.1f} tweets per min\")  #.1f ==> chỉ để 1 dấu sau dấu phẩy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JaMMbJ_nIHez"
   },
   "outputs": [],
   "source": [
    "east = {'date': datetime(2007, 4, 20, 0, 0), 'price': 1232443}\n",
    "west = {'date': datetime(2006, 5, 26, 0, 0), 'price': 1432673}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fnneOeD9Ilhl"
   },
   "source": [
    "The price for a house in the east neighborhood was $1232443 in 04-20-2007\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H6VcHIpRIA7g",
    "outputId": "0a24d3bb-ba6a-4c4d-c505-be2f41b796b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The price for a house in the east neighborhood was $1232443 in 04-20-2007\n"
     ]
    }
   ],
   "source": [
    "# Access values of date and price in east dictionary\n",
    "print(f\"The price for a house in the east neighborhood was ${east['price']} in {east['date']:%m-%d-%Y}\")  # %d -> hiện tháng = số   %B -> hiện tháng = chữ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eHBKpyBFI49w"
   },
   "source": [
    "<b> Regular Expression <b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r6EQapuFJu-I"
   },
   "source": [
    "The company that you are working for asked you to perform a sentiment analysis using a dataset with tweets. First of all, you need to do some cleaning and extract some information.\n",
    "While printing out some text, you realize that some tweets contain user mentions. Some of these mentions follow a very strange pattern. A few examples that you notice: @robot3!, @robot5& and @robot7#\n",
    "\n",
    "To analyze if those users are bots, you will do a proof of concept with one tweet and extract them using the .findall() method.\n",
    "\n",
    "You write down some helpful metacharacters to help you later: <br>\n",
    "\n",
    "\\d: digit (số) <br>\n",
    "\\w: word character (chữ) <br>\n",
    "\\W: non-word character (ko phải chữ) <br>\n",
    "\\s: whitespace (số)\n",
    "\n",
    "Công ty bạn đang làm đề nghị bạn làm 1 cái sentiment analysis bằng dữ liệu từ tweets. Bạn cần phải làm 1its cleaning và extract thông tin. \n",
    "\n",
    "Bạn notice 1 vài tweets chứa user mentions, nhưng có rất nhiều ký tự đặc biệt, bạn muốn check chúng có phải là bots không, bạn sẽ bóc hết các users lạ đó ra bằng cách sử dụng regular expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j2QBI2TGJ3h4"
   },
   "outputs": [],
   "source": [
    "sentiment_analysis = '@robot9! @robot4& I have a good feeling that the show isgoing to be amazing! @robot9$ @robot7%'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hIf-yR5BI7mM",
    "outputId": "b17d0ef1-3906-4a17-be73-3dfdbae445c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@robot9!', '@robot4&', '@robot9$', '@robot7%']\n"
     ]
    }
   ],
   "source": [
    "# Import the re module\n",
    "import re\n",
    "\n",
    "# Write the regex \n",
    "regex = r\"@robot\\d\\W\"\n",
    "\n",
    "# Find all matches of regex\n",
    "print(re.findall(regex, sentiment_analysis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "amfV1iPsKvLc"
   },
   "outputs": [],
   "source": [
    "sentiment_analysis = \"Unfortunately one of those moments wasn't a giant squid monster. User_mentions:2, likes: 9, number of retweets: 7\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8hh0VpAQKp6-",
    "outputId": "4acec1d4-c6e1-4a50-b764-7e6406d3e539"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['User_mentions:2']\n"
     ]
    }
   ],
   "source": [
    "# Write a regex to obtain user mentions\n",
    "print(re.findall(r\"User_mentions:\\d\", sentiment_analysis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g-dtjLrFLJ-K"
   },
   "outputs": [],
   "source": [
    "sentiment_analysis = 'He#newHis%newTin love with$newPscrappy. #8break%He is&newYmissing him@newLalready'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ni7K9ZqFLV1V"
   },
   "source": [
    "Some of the tweets in your dataset were downloaded incorrectly. Instead of having spaces to separate words, they have strange characters. You decide to use regular expressions to handle this situation. You print some of these tweets to understand which pattern you need to match.\n",
    "\n",
    "You notice that the sentences are always separated by a special character, followed by a number, the word break, and after that, another special character, e.g &4break!. The words are always separated by a special character, the word new, and a normal random character, e.g #newH.\n",
    "\n",
    "1 vài tweet được download sai cách, thay vì cách khoảng, chúng lại để lại ký tự đặc biệt, bạn muốn dùng regex để handle những trường hợp này. \n",
    "\n",
    "Bạn ghi nhận rằng những câu đó luôn bị chia cách bởi ký tự đặc biệt, theo sau bởi 1 số , và \"break\", và lại 1 ký tự lạ. Hoặc 1 ký tự đặc biệt, \"new\" và 1 ký tự bình thường. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y4HyQJYoLB0p",
    "outputId": "647f5d0e-1264-4bbe-b109-f213d7340992"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He is in love with scrappy.  He is missing him already\n"
     ]
    }
   ],
   "source": [
    "# Write a regex to match pattern separating sentences\n",
    "regex_sentence = r\"\\W\\dbreak\\W\"\n",
    "\n",
    "# Replace the regex_sentence with a space\n",
    "sentiment_sub = re.sub(regex_sentence, \" \", sentiment_analysis)\n",
    "\n",
    "# Write a regex to match pattern separating words\n",
    "regex_words = r\"\\Wnew\\w\"\n",
    "\n",
    "# Replace the regex_words and print the result\n",
    "sentiment_final = re.sub(regex_words, \" \", sentiment_sub)\n",
    "print(sentiment_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gJXVVacGMAW2"
   },
   "outputs": [],
   "source": [
    "sentiment_analysis = ['Boredd. Colddd @blueKnight39 Internet keeps stuffing up. Save me! https://www.tellyourstory.com'\n",
    ",\"I had a horrible nightmare last night @anitaLopez98 @MyredHat31 which affected my sleep, now I'm really tired\"\n",
    "'im lonely  keep me company @YourBestCompany! @foxRadio https://radio.foxnews.com 22 female, new york'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FJl8njHxMucV"
   },
   "source": [
    "Back to your Twitter sentiment analysis project! There are several types of strings that increase your sentiment analysis complexity. But these strings do not provide any useful sentiment. Among them, we can have links and user mentions.\n",
    "\n",
    "In order to clean the tweets, you want to extract some examples first. You know that most of the times links start with http and do not contain any whitespace, e.g. https://www.datacamp.com. User mentions start with @ and can have letters and numbers only, e.g. @johnsmith3.\n",
    "\n",
    "You write down some helpful quantifiers to help you: * zero or more times, + once or more, ? zero or once.\n",
    "\n",
    "Back lại project sentiment analysis của bạn. Có 1 vài kiểu chuỗi phức tạp làm tăng độ khó của mô hình, nhưng những chuỗi đó không mang lại thông tin hữu ích, ví dụ chúng chứa links và user mentions. Và bạn muốn làm sạch chúng. \n",
    "\n",
    "Bạn note lại là link thì thường bắt đầu bằng https và không có khoảng cách và user mention thì bắt đầu bằng @ và chỉ có chữ hoặc số. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cQRIuxxCMIYX",
    "outputId": "086c6b5d-9b3d-4548-dc0b-db309970a76e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.tellyourstory.com']\n",
      "['@blueKnight39']\n",
      "['https://radio.foxnews.com']\n",
      "['@anitaLopez98', '@MyredHat31', '@YourBestCompany', '@foxRadio']\n"
     ]
    }
   ],
   "source": [
    "# Import re module\n",
    "import re\n",
    "\n",
    "for tweet in sentiment_analysis:\n",
    "  \t# Write regex to match http links and print out result\n",
    "\tprint(re.findall(r\"http\\S+\", tweet))   #\\S -> ko phải là khoảng trắng, + -> ký tự đứng trước có thể trùng lặp\n",
    "\n",
    "\t# Write regex to match user mentions and print out result\n",
    "\tprint(re.findall(r\"@\\w+\", tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x7dbqS55M4N-"
   },
   "outputs": [],
   "source": [
    "sentiment_analysis = ['I would like to apologize for the repeated Video Games Live related tweets. 32 minutes ago'\n",
    ",'@zaydia but i cant figure out how to get there / back / pay for a hotel 1st May 2019'\n",
    ",'FML: So much for seniority, bc of technological ineptness 23rd June 2018 17:54'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "md5tCHG3Mzsh"
   },
   "source": [
    "Đôi khi chuỗi lại chứa ngày tháng, thời giangian và ban cũng muốn lọc luôn những chuỗi đó. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K8Eu7-GwMzLE",
    "outputId": "e12d7b61-0fc8-4303-ae09-65ed25bc6e00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['1st May 2019']\n",
      "['23rd June 2018']\n"
     ]
    }
   ],
   "source": [
    "# Complete the for loop with a regex to find dates\n",
    "for date in sentiment_analysis:\n",
    "\tprint(re.findall(r\"\\d{1,2}\\w+\\s\\w+\\s\\d{4}\", date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pUi8u6tINn_z",
    "outputId": "4ab08432-ae39-4fa9-bf37-78b6f17b5e83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['32 minutes ago']\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for date in sentiment_analysis:\n",
    "\tprint(re.findall(r\"\\d{1,2}\\s\\w+\\sago\", date)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xrM-fi-CNa82",
    "outputId": "d418a2c5-7367-46e5-fd15-bfdfe5e2cd40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "['23rd June 2018 17:54']\n"
     ]
    }
   ],
   "source": [
    "# Complete the for loop with a regex to find dates\n",
    "for date in sentiment_analysis:\n",
    "\tprint(re.findall(r\"\\d{1,2}\\w+\\s\\w+\\s\\d{4}\\s\\d{1,2}:\\d{2}\", date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nVH0wD2zN8-D"
   },
   "source": [
    "Your next step is to tokenize the text of your tweets. Tokenization is the process of breaking a string into lexical units or, in simpler terms, words. But first, you need to remove hashtags so they do not cloud your process. You realize that hashtags start with a # symbol and contain letters and numbers but never whitespace. After that, you plan to split the text at whitespace matches to get the tokens.\n",
    "\n",
    "You bring your list of quantifiers to help you: * zero or more times, + once or more, ? zero or once, {n, m} minimum n, maximum m.\n",
    "\n",
    "Bạn muốn tokenize text từ các tweet, lấy ra những thông tin có íchích"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PrA-lfMeN9vb"
   },
   "outputs": [],
   "source": [
    "sentiment_analysis = 'ITS NOT ENOUGH TO SAY THAT IMISS U #MissYou #SoMuch #Friendship #Forever'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2fNA-1-sOCkP",
    "outputId": "c1452310-b99a-4382-be01-21cde27da1b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ITS', 'NOT', 'ENOUGH', 'TO', 'SAY', 'THAT', 'IMISS', 'U', '']\n"
     ]
    }
   ],
   "source": [
    "# Write a regex matching the hashtag pattern / Loại bỏ các hashtag \n",
    "regex = r\"#\\w+\"\n",
    "\n",
    "# Replace the regex by an empty string\n",
    "no_hashtag = re.sub(regex, \"\", sentiment_analysis)\n",
    "\n",
    "# Get tokens by splitting text\n",
    "print(re.split(r\"\\s+\",no_hashtag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZHhlWqLdOmmU"
   },
   "outputs": [],
   "source": [
    "sentiment_analysis = ['AIshadowhunters.txt aaaaand back to my literature review. At least i have a friendly cup of coffee to keep me company'\n",
    ",\"ouMYTAXES.txt I am worried that I won't get my $900 even though I paid tax last year\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZwdFYcK6O4sZ",
    "outputId": "d0a6558d-b4ee-4226-dcae-640f339f24f0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AIshadowhunters.txt aaaaand back to my literature review. At least i have a friendly cup of coffee to keep me company',\n",
       " \"ouMYTAXES.txt I am worried that I won't get my $900 even though I paid tax last year\"]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9a1jQBh8O36g"
   },
   "source": [
    "You are not satisfied with your tweets dataset cleaning. There are still extra strings that do not provide any sentiment. Among them are strings that refer to text file names.\n",
    "\n",
    "You also find a way to detect them:\n",
    "\n",
    "They appear at the start of the string.\n",
    "They always start with a sequence of 2 or 3 upper or lowercase vowels (a e i o u).\n",
    "They always finish with the txt ending.\n",
    "You are not sure if you should remove them directly. So you write a script to find and store them in a separate dataset.\n",
    "\n",
    "You write down some metacharacters to help you: ^ anchor to beginning, . any character.\n",
    "\n",
    "Bạn vẫn chưa thỏa mãn với kết quả thu được, có nhiều chuỗi không chứa thông tin sentiment, đôi khi chúng chứa thông tin text file được crawl theo. Và bạn muốn lọc chúng ra \n",
    "\n",
    "Bạn note là text file luôn kết thúc với đuôi .txt và bắt đầu bởi 1 sequence từ 2 - 3 những nguyên âm a i u e o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DZdBPGP9OirG",
    "outputId": "8a42bad3-76bc-4ae3-b119-26f7e0669a33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AIshadowhunters.txt']\n",
      " aaaaand back to my literature review. At least i have a friendly cup of coffee to keep me company\n",
      "['ouMYTAXES.txt']\n",
      " I am worried that I won't get my $900 even though I paid tax last year\n"
     ]
    }
   ],
   "source": [
    "# Write a regex to match text file name\n",
    "regex = r\"\\w+.txt\"\n",
    "\n",
    "for text in sentiment_analysis:\n",
    "\t# Find all matches of the regex\n",
    "\tprint(re.findall(regex, text))\n",
    "    \n",
    "\t# Replace all matches with empty string\n",
    "\tprint(re.sub(regex, \"\", text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UtZh9e5WPMZW"
   },
   "source": [
    "A colleague has asked for your help! When a user signs up on the company website, they must provide a valid email address.\n",
    "The company puts some rules in place to verify that the given email address is valid:\n",
    "\n",
    "The first part can contain:\n",
    "Upper A-Z or lowercase letters a-z\n",
    "Numbers\n",
    "Characters: !, #, %, &, *, $, .\n",
    "Must have @\n",
    "Domain:\n",
    "Can contain any word characters\n",
    "But only .com ending is allowed\n",
    "The project consist of writing a script that checks if the email address follow the correct pattern. Your colleague gave you a list of email addresses as examples to test.\n",
    "\n",
    "Một đồng nghiệp nhờ bạn giúp check đâu là những email hợp lệ. \n",
    "Rules của 1 email hợp lệ 🇰\n",
    "phải có @ , trước đó thì có thể chứa chuỗi hoặc số, viết hoa lẫn viết thường , các ký tự đặc biệt ! , # , % , &, $,*,.\n",
    "Domain thì chữ nào cũng được nhưng phải kết thúc bằng .comcom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qRkoPLcFPTXN"
   },
   "outputs": [],
   "source": [
    "emails = ['n.john.smith@gmail.com', '87victory@hotmail.com', '!#mary-=@msca.net']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lk0MmEyVPZ3q",
    "outputId": "1a72a209-0200-4271-aa88-cd2175655356"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The email n.john.smith@gmail.com is a valid email\n",
      "The email 87victory@hotmail.com is a valid email\n",
      "The email !#mary-=@msca.net is invalid\n"
     ]
    }
   ],
   "source": [
    "# Write a regex to match a valid email address\n",
    "regex = r\"[A-Za-z0-9!#%&*\\$\\.]+@\\w+\\.com\"\n",
    "\n",
    "for example in emails:\n",
    "  \t# Match the regex to the string\n",
    "    if re.match(regex, example):\n",
    "        # Complete the format method to print out the result\n",
    "      \tprint(\"The email {email_example} is a valid email\".format(email_example=example))\n",
    "    else:\n",
    "      \tprint(\"The email {email_example} is invalid\".format(email_example=example))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HuH2rT7JPl6m"
   },
   "source": [
    "The second part of the website project is to write a script that validates the password entered by the user. The company also puts some rules in order to verify valid passwords:\n",
    "\n",
    "It can contain lowercase a-z and uppercase letters A-Z\n",
    "It can contain numbers\n",
    "It can contain the symbols: *, #, $, %, !, &, .\n",
    "It must be at least 8 characters long but not more than 20\n",
    "Your colleague also gave you a list of passwords as examples to test.\n",
    "\n",
    "Phần thứ 2 của website project là phải check password hợp lệ. \n",
    "\n",
    "Rules của password 🇰\n",
    "Lowercase từ a - z hoặc uppercase \n",
    "có thể chứa số \n",
    "có thể chứa ký tự đặc biệt *, #, $, %, !, &, .\n",
    "tối thiểu 8 ký tự nhưng không vượt quá 20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ck0KLpzEPlbE"
   },
   "outputs": [],
   "source": [
    "passwords = ['Apple34!rose', 'My87hou#4$', 'abc123']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N8uGlQ7_Pkq8",
    "outputId": "fd7360f4-acd4-4de5-e4e1-b14f0d068ee3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The password Apple34!rose is a valid password\n",
      "The password My87hou#4$ is a valid password\n",
      "The password abc123 is invalid\n"
     ]
    }
   ],
   "source": [
    "# Write a regex to match a valid password\n",
    "regex = r\"[A-Za-z0-9*#$%!&.]{8,20}\"\n",
    "\n",
    "for example in passwords:\n",
    "  \t# Scan the strings to find a match\n",
    "    if re.findall(regex, example):\n",
    "        # Complete the format method to print out the result\n",
    "      \tprint(\"The password {pass_example} is a valid password\".format(pass_example=example))\n",
    "    else:\n",
    "      \tprint(\"The password {pass_example} is invalid\".format(pass_example=example))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AOhnttGVP3Hv"
   },
   "outputs": [],
   "source": [
    "#You need to keep working and cleaning your tweets dataset. You realize that there are some HTML tags present. You need to remove them but keep the inside content as they are useful for analysis.\n",
    "\n",
    "#Let's take a look at this sentence containing an HTML tag:\n",
    "#\n",
    "#I want to see that <strong>amazing show</strong> again!.\n",
    "#\n",
    "#You know that to get the HTML tag you need to match anything that sits inside angle brackets < >. But the biggest problem is that the closing tag has the same structure. If you match too much, you will end up removing key information. So you need to decide whether to use a greedy or a lazy quantifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LG0e18XM4YgW"
   },
   "source": [
    "Bạn tiếp tục clean dữ liệu tweet, bạn thấy có 1 vài html tag và bạn muốn remove những html tag đó "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xO4cN8-iQSoX"
   },
   "outputs": [],
   "source": [
    "string = 'I want to see that <strong>amazing show</strong> again!'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UxntlsWcQN3y",
    "outputId": "1be12aae-12c4-4083-c7ec-eba0603d9c3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want to see that amazing show again!\n"
     ]
    }
   ],
   "source": [
    "# Import re\n",
    "import re\n",
    "\n",
    "# Write a regex to eliminate tags\n",
    "string_notags = re.sub(r\"<.+?>\", \"\", string)\n",
    "\n",
    "# Print out the result\n",
    "print(string_notags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bHJTgU9mQdA9"
   },
   "source": [
    "Next, you see that numbers still appear in the text of the tweets. So, you decide to find all of them.\n",
    "\n",
    "Let's imagine that you want to extract the number contained in the sentence I was born on April 24th. A lazy quantifier will make the regex return 2 and 4, because they will match as few characters as needed. However, a greedy quantifier will return the entire 24 due to its need to match as much as possible.\n",
    "\n",
    "Bạn muốn lọc số từ tweet ra , và bạn phân vân giữa 2 phương pháp greedy và lazy quantifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pAZqlHA8QlDv"
   },
   "outputs": [],
   "source": [
    "sentiment_analysis = 'Was intending to finish editing my 536-page novel manuscript tonight, but that will probably not happen. And only 12 pages are left '\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DkjXADsEQeUh"
   },
   "source": [
    "<b> Greedy matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_VFQwC2LQdqH",
    "outputId": "57a8b5b6-0949-4d51-8aa3-aecef5b410d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5', '3', '6', '1', '2']\n"
     ]
    }
   ],
   "source": [
    "# Write a lazy regex expression \n",
    "numbers_found_lazy = re.findall(r\"\\d+?\", sentiment_analysis)\n",
    "\n",
    "# Print out the result\n",
    "print(numbers_found_lazy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J4SyAbv-QqGV"
   },
   "source": [
    "<b> Non Greedy matching (lazy matching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c99iShvyQs4a",
    "outputId": "c426e15c-b73c-4db2-8b62-9a1aa2de2f59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['536', '12']\n"
     ]
    }
   ],
   "source": [
    "# Write a greedy regex expression \n",
    "numbers_found_greedy = re.findall(r\"\\d+\", sentiment_analysis)\n",
    "\n",
    "# Print out the result\n",
    "print(numbers_found_greedy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K1xAxXAjROZi"
   },
   "source": [
    "<b> Lazy approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FE8udXWvRR3O"
   },
   "outputs": [],
   "source": [
    "sentiment_analysis = \"Put vacation photos online (They were so cute) a few yrs ago. PC crashed, and now I forget the name of the site (I'm crying). \"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d1lSby95RcR8"
   },
   "source": [
    "Use a greedy quantifier to match text that appears within parentheses in the variable sentiment_analysis.\n",
    "\n",
    "Dùng greedy quantifier để match text trong ( ) trong chuỗi sentiment_analysis\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jv7WuFiVRJZj",
    "outputId": "6c65aeb7-6997-43c0-d24b-645511ba91ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"(They were so cute) a few yrs ago. PC crashed, and now I forget the name of the site (I'm crying)\"]\n"
     ]
    }
   ],
   "source": [
    "# Write a greedy regex expression to match \n",
    "sentences_found_greedy = re.findall(r\"\\(.*\\)\", sentiment_analysis)\n",
    "\n",
    "# Print out the result\n",
    "print(sentences_found_greedy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zlrd2YFIRhPX"
   },
   "source": [
    "Now, use a lazy quantifier to match text that appears within parentheses in the variable sentiment_analysis.\n",
    "Dùng lazylazy quantifier để match text trong ( ) trong chuỗi sentiment_analysisanalysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wWyBK9k-RLB-",
    "outputId": "469109b4-2fcd-4607-d493-9780f294e810"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(They were so cute)', \"(I'm crying)\"]\n"
     ]
    }
   ],
   "source": [
    "# Write a lazy regex expression\n",
    "sentences_found_lazy = re.findall(r\"\\(.*?\\)\", sentiment_analysis)\n",
    "\n",
    "# Print out the results\n",
    "print(sentences_found_lazy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uu5kyXswRsy2"
   },
   "source": [
    "You are still working on your Twitter sentiment analysis. You analyze now some things that caught your attention. You noticed that there are email addresses inserted in some tweets. Now, you are curious to find out which is the most common name.\n",
    "\n",
    "You want to extract the first part of the email. E.g. if you have the email marysmith90@gmail.com, you are only interested in marysmith90.\n",
    "You need to match the entire expression. So you make sure to extract only names present in emails. Also, you are only interested in names containing upper (e.g. A,B, Z) or lowercase letters (e.g. a, d, z) and numbers.\n",
    "\n",
    "Bạn vẫn tiếp tục làm sentiment analysis, bạn ghi nhận có nhiều email được đề cập, bạn muốn tìm ra đâu là email được đề cập nhiều nhất. \n",
    "\n",
    "Bạn chỉ muốn lấy phần trước chữ @, chúng có thể chứa bất kỳ chuỗi viết thường hoặc viết hoa, và số. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "roVM6WzORwOe"
   },
   "outputs": [],
   "source": [
    "sentiment_analysis = ['Just got ur newsletter, those fares really are unbelievable. Write to statravelAU@gmail.com or statravelpo@hotmail.com. They have amazing prices',\n",
    " 'I should have paid more attention when we covered photoshop in my webpage design class in undergrad. Contact me Hollywoodheat34@msn.net.',\n",
    " 'hey missed ya at the meeting. Read your email! msdrama098@hotmail.com']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8tKlmNPzRtK0",
    "outputId": "8982346b-c1e0-454b-bfad-570e2d272b57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lists of users found in this tweet: ['statravelAU', 'statravelpo']\n",
      "Lists of users found in this tweet: ['Hollywoodheat34']\n",
      "Lists of users found in this tweet: ['msdrama098']\n"
     ]
    }
   ],
   "source": [
    "# Write a regex that matches email\n",
    "regex_email = r\"([A-Za-z0-9]+)@\\S+\"\n",
    "\n",
    "for tweet in sentiment_analysis:\n",
    "    # Find all matches of regex in each tweet\n",
    "    email_matched = re.findall(regex_email, tweet)\n",
    "\n",
    "    # Complete the format method to print the results\n",
    "    print(\"Lists of users found in this tweet: {}\".format(email_matched))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kAnPk2jbS5c3"
   },
   "source": [
    "Your boss assigned you to a small project. They are performing an analysis of the travels people made to attend business meetings. You are given a dataset with only the email subjects for each of the people traveling.\n",
    "\n",
    "You learn that the text followed a pattern. Here is an example:\n",
    "\n",
    "Here you have your boarding pass LA4214 AER-CDB 06NOV.\n",
    "\n",
    "You need to extract the information about the flight:\n",
    "\n",
    "The two letters indicate the airline (e.g LA),\n",
    "The 4 numbers are the flight number (e.g. 4214).\n",
    "The three letters correspond to the departure (e.g AER),\n",
    "The destination (CDB),\n",
    "The date (06NOV) of the flight.\n",
    "All letters are always uppercase.\n",
    "\n",
    "Sếp của bạn assign cho bạn 1 project nhỏ, phân tích chuyến bay mà mọi người dùng để đi dự các buổi họp. Bạn muốn lấy thông tin từ boarding pass \n",
    "\n",
    "Các thông tin có quy luật của nó \n",
    "2 chữ đầu là tên hãng hàng không\n",
    "4 chữ số tiếp theo là flight number\n",
    "3 chữ tiếp theo là nơi đi\n",
    "3 chữ tiếp theo là nơi đến\n",
    "những ký tự sau đó là ngày bay. \n",
    "Tất cả ký tự chữ đều là in hoa "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JZIhDdn6S8vX"
   },
   "outputs": [],
   "source": [
    "flight = 'Subject: You are now ready to fly. Here you have your boarding pass IB3723 AMS-MAD 06OCT'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HJigw44VS592",
    "outputId": "c8e9d448-cbdd-46be-9a38-7d855abc34be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Airline: IB Flight number: 3723\n",
      "Departure: AMS Destination: MAD\n",
      "Date: 06OCT\n"
     ]
    }
   ],
   "source": [
    "# Import re\n",
    "import re\n",
    "\n",
    "# Write regex to capture information of the flight\n",
    "regex = r\"([A-Z]{2})(\\d{4})\\s([A-Z]{3})-([A-Z]{3})\\s(\\d{2}[A-Z]{3})\"\n",
    "\n",
    "# Find all matches of the flight information\n",
    "flight_matches = re.findall(regex, flight)\n",
    "    \n",
    "#Print the matches\n",
    "print(\"Airline: {} Flight number: {}\".format(flight_matches[0][0], flight_matches[0][1]))\n",
    "print(\"Departure: {} Destination: {}\".format(flight_matches[0][2], flight_matches[0][3]))\n",
    "print(\"Date: {}\".format(flight_matches[0][4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3NuyjmqzUfd3"
   },
   "source": [
    "You are still working on the Twitter sentiment analysis project. First, you want to identify positive tweets about movies and concerts.\n",
    "\n",
    "You plan to find all the sentences that contain the words love, like, or enjoy and capture that word. You will limit the tweets by focusing on those that contain the words movie or concert by keeping the word in another group. You will also save the movie or concert name.\n",
    "\n",
    "For example, if you have the sentence: I love the movie Avengers. You match and capture love. You need to match and capture movie. Afterwards, you match and capture anything until the dot.\n",
    "\n",
    "Bạn vẫn làm sentiment analysis. Bạn muốn lọc ra những positive tweets. \n",
    "\n",
    "Bạn muốn tìm tất cả câu có chứa từ love, like hoặc enjoy và lưu lại nhưunxg từ đó, nhưng bạn chỉ lưu nếu tweet đó cũng có chứa movie hoặc concert, bạn cũng muốn lưu lại tên của movie hoặc concert. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hb7ZFS0wUkZ4"
   },
   "outputs": [],
   "source": [
    "sentiment_analysis = ['I totally love the concert The Book of Souls World Tour. It kinda amazing!',\n",
    " 'I enjoy the movie Wreck-It Ralph. I watched with my boyfriend.',\n",
    " \"I still like the movie Wish Upon a Star. Too bad Disney doesn't show it anymore.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U7A41WdcUiQp",
    "outputId": "184aff50-72b7-4345-cddd-1aea66fc0481"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive comments found [('love', 'concert', 'The Book of Souls World Tour')]\n",
      "Positive comments found [('enjoy', 'movie', 'Wreck-It Ralph')]\n",
      "Positive comments found [('like', 'movie', 'Wish Upon a Star')]\n"
     ]
    }
   ],
   "source": [
    "# Write a regex that matches sentences with the optional words\n",
    "regex_positive = r\"(love|like|enjoy).+?(movie|concert)\\s(.+?)\\.\"\n",
    "\n",
    "for tweet in sentiment_analysis:\n",
    "\t# Find all matches of regex in tweet\n",
    "    positive_matches = re.findall(regex_positive, tweet)\n",
    "    \n",
    "    # Complete format to print out the results\n",
    "    print(\"Positive comments found {}\".format(positive_matches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qQlg_dH_Uzg1"
   },
   "source": [
    "After finding positive tweets, you want to do it for negative tweets. Your plan now is to find sentences that contain the words hate, dislike or disapprove. You will again save the movie or concert name. You will get the tweet containing the words movie or concert but this time, you don't plan to save the word.\n",
    "\n",
    "For example, if you have the sentence: I dislike the movie Avengers a lot.. You match and capture dislike. You will match but not capture the word movie. Afterwards, you match and capture anything until the dot.\n",
    "\n",
    "Tương tự ,bạn muốn lọc ra negative tweet, bạn sẽ tìm hết các sentences có chứa những từ hate , dislike hoặc disapprove. Bạn cũng sẽ lưu lại movie, concert và tên của chúng. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t-UINdjkU6L_"
   },
   "outputs": [],
   "source": [
    "sentiment_analysis = ['That was horrible! I really dislike the movie The cabin and the ant. So boring.',\n",
    " \"I disapprove the movie Honest with you. It's full of cliches.\",\n",
    " 'I dislike very much the concert After twelve Tour. The sound was horrible.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GsNsd6_YU0cs",
    "outputId": "0db09c18-fb06-4c4f-cbb1-9fd9356cba42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative comments found [('dislike', 'The cabin and the ant')]\n",
      "Negative comments found [('disapprove', 'Honest with you')]\n",
      "Negative comments found [('dislike', 'After twelve Tour')]\n"
     ]
    }
   ],
   "source": [
    "# Write a regex that matches sentences with the optional words\n",
    "regex_negative = r\"(hate|dislike|disapprove).+?(?:movie|concert)\\s(.+?)\\.\"\n",
    "\n",
    "for tweet in sentiment_analysis:\n",
    "\t# Find all matches of regex in tweet\n",
    "    negative_matches = re.findall(regex_negative, tweet)\n",
    "    \n",
    "    # Complete format to print out the results\n",
    "    print(\"Negative comments found {}\".format(negative_matches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R-jW2TX-VXAw"
   },
   "source": [
    "You now need to work on another small project you have been delaying. Your company gave you some PDF files of signed contracts. The goal of the project is to create a database with the information you parse from them. Three of these columns should correspond to the day, month, and year when the contract was signed.\n",
    "The dates appear as Signed on 05/24/2016 (05 indicating the month, 24 the day). You decide to use capturing groups to extract this information. Also, you would like to retrieve that information so you can store it separately in different variables.\n",
    "\n",
    "You decide to do a proof of concept.\n",
    "\n",
    "Bạn muốn lọc ra thông tin ngày , tháng , năm của hợp đồng đã ký trong file pdf. \n",
    "Bạn note lại ngày ký hợp đồng đứng sau chữ \"Signed onon\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0fJwamf7VYt-"
   },
   "outputs": [],
   "source": [
    "contract = 'Provider will invoice Client for Services performed within 30 days of performance.  Client will pay Provider as set forth in each Statement of Work within 30 days of receipt and acceptance of such invoice. It is understood that payments to Provider for services rendered shall be made in full as agreed, without any deductions for taxes of any kind whatsoever, in conformity with Provider’s status as an independent contractor. Signed on 03/25/2001.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xj8feXuuVXZQ",
    "outputId": "a2d68e68-95d2-4a58-dc69-0eb2fe3aeef8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our first contract is dated back to 2001. Particularly, the day 25 of the month 03.\n"
     ]
    }
   ],
   "source": [
    "# Write regex and scan contract to capture the dates described\n",
    "regex_dates = r\"Signed\\son\\s(\\d{2})/(\\d{2})/(\\d{4})\"\n",
    "dates = re.search(regex_dates, contract)\n",
    "\n",
    "# Assign to each key the corresponding match\n",
    "signature = {\n",
    "\t\"day\": dates.group(2),\n",
    "\t\"month\": dates.group(1),\n",
    "\t\"year\": dates.group(3)\n",
    "}\n",
    "# Complete the format method to print-out\n",
    "print(\"Our first contract is dated back to {data[year]}. Particularly, the day {data[day]} of the month {data[month]}.\".format(data=signature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NotL-Jk0VsOJ"
   },
   "outputs": [],
   "source": [
    "#In the meantime, you are working on one of your other projects. The company is going to develop a new product. \n",
    "#It will help developers automatically check the code they are writing. \n",
    "#You need to write a short script for checking that every HTML tag that is open has its proper closure.\n",
    "#\n",
    "#You have an example of a string containing HTML tags:\n",
    "#\n",
    "#<title>The Data Science Company</title>\n",
    "#\n",
    "#You learn that an opening HTML tag is always at the beginning of the string. It appears inside <>. A closing tag also appears inside <>, but it is preceded by /.\n",
    "#\n",
    "#You also remember that capturing groups can be referenced using numbers, e.g \\4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FXkqL9ob7Nak"
   },
   "source": [
    "Bạn muốn viết 1 script check code html cho các dev, và các html tag đó phải đúng cú pháp. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nydE85XcV5Xt"
   },
   "outputs": [],
   "source": [
    "html_tags = ['<body>Welcome to our course! It would be an awesome experience</body>',\n",
    " '<article>To be a data scientist, you need to have knowledge in statistics and mathematics</article>',\n",
    " '<nav>About me Links Contact me!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dmpQyfjtV4PJ",
    "outputId": "32dd8dca-579c-400a-c790-532809cffbda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your tag body is closed\n",
      "Your tag article is closed\n",
      "Close your nav tag!\n"
     ]
    }
   ],
   "source": [
    "for string in html_tags:\n",
    "    # Complete the regex and find if it matches a closed HTML tags\n",
    "    match_tag =  re.match(r\"<(\\w+)>.*?</\\1>\", string)\n",
    " \n",
    "    if match_tag:\n",
    "        # If it matches print the first group capture\n",
    "        print(\"Your tag {} is closed\".format(match_tag.group(1))) \n",
    "    else:\n",
    "        # If it doesn't match capture only the tag \n",
    "        notmatch_tag = re.match(r\"<(\\w+)>\", string)\n",
    "        # Print the first group capture\n",
    "        print(\"Close your {} tag!\".format(notmatch_tag.group(1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JUlvcjiTWLAn"
   },
   "source": [
    "Back to your sentiment analysis! Your next task is to replace elongated words that appear in the tweets. We define an elongated word as a word that contains a repeating character twice or more times. e.g. \"Awesoooome\".\n",
    "\n",
    "Replacing those words is very important since a classifier will treat them as a different term from the source words lowering their frequency.\n",
    "\n",
    "To find them, you will use capturing groups and reference them back using numbers. E.g \\4.\n",
    "\n",
    "If you want to find a match for Awesoooome. You first need to capture Awes. Then, match o and reference the same character back, and then, me.\n",
    "\n",
    "Ở project sentiment analysis, bạn muốn fix những ký tự được kéo dài , ví dụ \"Awesooooome\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rVDXkqflWM7w"
   },
   "outputs": [],
   "source": [
    "sentiment_analysis = ['@marykatherine_q i know! I heard it this morning and wondered the same thing. Moscooooooow is so behind the times',\n",
    " 'Staying at a friends house...neighborrrrrrrs are so loud-having a party',\n",
    " 'Just woke up an already have read some e-mail']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "41h9MXZ-WL9f",
    "outputId": "ffec83e3-78cc-4d07-8e45-ae5508c3fe25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elongated word found: Moscooooooow\n",
      "Elongated word found: neighborrrrrrrs\n",
      "No elongated word found\n"
     ]
    }
   ],
   "source": [
    "# Complete the regex to match an elongated word\n",
    "regex_elongated = r\"\\w*(\\w)\\1\\w*\"\n",
    "\n",
    "for tweet in sentiment_analysis:\n",
    "\t# Find if there is a match in each tweet \n",
    "\tmatch_elongated = re.search(regex_elongated, tweet)\n",
    "    \n",
    "\tif match_elongated:\n",
    "\t\t# Assign the captured group zero \n",
    "\t\telongated_word = match_elongated.group(0)\n",
    "        \n",
    "\t\t# Complete the format method to print the word\n",
    "\t\tprint(\"Elongated word found: {word}\".format(word=elongated_word))\n",
    "\telse:\n",
    "\t\tprint(\"No elongated word found\")     \t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jiT0R5nvWkKA"
   },
   "source": [
    "Now, you want to perform some visualizations with your sentiment_analysis dataset. You are interested in the words surrounding python. You want to count how many times a specific words appears right before and after it.\n",
    "\n",
    "Positive lookahead (?=) makes sure that first part of the expression is followed by the lookahead expression. Positive lookbehind (?<=) returns all matches that are preceded by the specified pattern.\n",
    "\n",
    "Bạn muốn visualize dữ liệu từ dataset sentiment analysis, bạn muốn tìm xem những chữ nào được nhắc đến nhiều nhất trước và sau chữ \"Python\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PnZPpUGIWo3u"
   },
   "outputs": [],
   "source": [
    "sentiment_analysis = 'You need excellent python skills to be a data scientist. Must be! Excellent python'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9rhOvzb-WnfF",
    "outputId": "82f27b73-1660-4a17-afa2-141d1e88678a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['excellent', 'Excellent']\n"
     ]
    }
   ],
   "source": [
    "# Positive lookahead\n",
    "look_ahead = re.findall(r\"\\w+(?=\\spython)\", sentiment_analysis)\n",
    "\n",
    "# Print out\n",
    "print(look_ahead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d52ba3QsWwNC",
    "outputId": "5ccdde8f-15e0-41fc-afc0-351feb3be462"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['skills']\n"
     ]
    }
   ],
   "source": [
    "# Positive lookbehind\n",
    "look_behind = re.findall(r\"(?<=[Pp]ython\\s)\\w+\", sentiment_analysis)\n",
    "\n",
    "# Print out\n",
    "print(look_behind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4MpHZKQCWzAm"
   },
   "source": [
    "Now, you need to write a script for a cell-phone searcher. It should scan a list of phone numbers and return those that meet certain characteristics.\n",
    "\n",
    "The phone numbers in the list have the structure:\n",
    "\n",
    "Optional area code: 3 numbers\n",
    "Prefix: 4 numbers\n",
    "Line number: 6 numbers\n",
    "Optional extension: 2 numbers\n",
    "E.g. 654-8764-439434-01.\n",
    "\n",
    "You decide to use .findall() and the non-capturing group's negative lookahead (?!) and negative lookbehind (?<!).\n",
    "\n",
    "Bạn viết 1 script scan số điện thoại và trả ra những số phù hợp theo các tiêu chí :\n",
    "\n",
    "Optional area code: 3 numbers\n",
    "Prefix: 4 numbers\n",
    "Line number: 6 numbers\n",
    "Optional extension: 2 numbers\n",
    "E.g. 654-8764-439434-01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eX13iwxJXDq6"
   },
   "outputs": [],
   "source": [
    "cellphones = ['4564-646464-01', '345-5785-544245', '6476-579052-01']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_tVt-JhuW0lw",
    "outputId": "40471362-c980-46ff-ffa0-013910475a96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4564-646464-01']\n",
      "[]\n",
      "['6476-579052-01']\n"
     ]
    }
   ],
   "source": [
    "#Get all cell phones numbers that are not preceded by the optional area code.\n",
    "for phone in cellphones:\n",
    "\t# Get all phone numbers not preceded by area code\n",
    "\tnumber = re.findall(r\"(?<!\\d{3}-)\\d{4}-\\d{6}-\\d{2}\", phone)\n",
    "\tprint(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N7HyMhiMXATh",
    "outputId": "39653c7a-ba3d-4c7a-c57e-0c1a3920300d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['345-5785-544245']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "#Get all the cell phones numbers that are not followed by the optional extension.\n",
    "for phone in cellphones:\n",
    "\t# Get all phone numbers not followed by optional extension\n",
    "\tnumber = re.findall(r\"\\d{3}-\\d{4}-\\d{6}(?!-\\d{2})\", phone)\n",
    "\tprint(number)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
